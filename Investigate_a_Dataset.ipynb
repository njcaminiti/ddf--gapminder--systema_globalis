{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating the Gapminder Systema Globalis Dataset\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "The name \"Systema Globalis\" is inspired by [Systema Naturae](https://en.wikipedia.org/wiki/Systema_Naturae); the first systematic compilation of all living things from year 1735, by the Swedish Scientist Carl von Linn√©. The goal of Systema Globalis is to compile all public statistics; Social, Economic and Environmental; into a comparable total dataset.\n",
    "\n",
    "### Data\n",
    "This is the main dataset used in tools on the official Gapminder website. It contains local &amp; global statistics combined from hundreds of sources.\n",
    "\n",
    "For the purposes of this demonstration, we will be using the glob module for file manipulation, pandas and numpy for working with the data, and matplotlib's basic pyplot suite for visualization.\n",
    "\n",
    "_This exercise is intended to illustrate the choices an analyst must make at each point of the data analysis process, from the initial data-wrangling to the final presentation of findings. The process shown is not being presented as an optimal route. Rather, the intent is to provide a realistic look at how an analyst might approach an unfamiliar dataset, including illustration of the potential pitfalls they may encounter._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    "The Systema Globalis data consists of longitudinal country-level data on over 500 indicators of social, economic, health, environmental, and other comparative measures. The data on each indicator is contained in its own csv file, organized by country (geo) and year of measurement (time). \n",
    "\n",
    "### General Properties\n",
    "\n",
    "Due to the multi-file structure of this dataset, analysis involving more than one indicator requires file operations to parse, read, and merge the data from each target indicator. The glob module simplifies this process, allowing for filename 'globbing' based on wildcard searches of filenames. This provides one method of subsetting the files and extracting only the data we are interested in analyzing. \n",
    "\n",
    "For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ddf--datapoints--literacy_rate_adult_female_percent_of_females_ages_15_above--by--geo--time.csv'\n",
      " 'ddf--datapoints--literacy_rate_adult_male_percent_of_males_ages_15_and_above--by--geo--time.csv'\n",
      " 'ddf--datapoints--literacy_rate_adult_total_percent_of_people_ages_15_and_above--by--geo--time.csv'] \n",
      "\n",
      "\n",
      "['ddf--datapoints--energy_from_solid_biofuels_percent--by--geo--time.csv'\n",
      " 'ddf--datapoints--energy_production_per_person--by--geo--time.csv'\n",
      " 'ddf--datapoints--energy_production_total--by--geo--time.csv']\n"
     ]
    }
   ],
   "source": [
    "# Returns only the filenames of 'datapoint' csv files containing literacy data:\n",
    "datafiles_literacy = glob.glob('*datapoints*literacy*.csv')\n",
    "print(np.array(datafiles_literacy)[:3], '\\n\\n')\n",
    "\n",
    "# Returns only the filenames of 'datapoint' csv files containing energy data:\n",
    "datafiles_energy = glob.glob('*datapoints*energy*.csv')\n",
    "print(np.array(datafiles_energy)[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the alternative, we can simply read all of the data into Python, and hold off on trimming it down or subsetting it until after its all been processed.  This will be more computationally intensive than importing only a target subset, and would be impractical (or even impossible) with very large datasets, but there is a certain appeal to compiling all of the relevant data in a single place and while complex, this dataset is not so large to make this too unweildly, so an analyst may opt for this route even though it may bring with it some complications.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafiles_all = glob.glob('*datapoints*.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gapminder data is particularly well suited to exploratory data analysis because it is largely 'pre-cleaned'. Each table shares a uniform format, making it very easy to read in and merge the data from multiple indicators. \n",
    "\n",
    "While data 'wrangling' can be a complex, time-consuming process, especially when dealing with messy data or data from multiple sources, it can be accomplished here with relative ease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty dictionary into which we will read all of our data files\n",
    "ref = {}\n",
    "\n",
    "# loop through filenames, extracting indicator name from filename, and values from each file itself\n",
    "for filename in datafiles_all:\n",
    "    key = filename.partition('datapoints--')[2].partition('--')[0]\n",
    "    data = pd.read_csv(filename)\n",
    "    # index each table by country and cast longitudinal progression to columns \n",
    "    data = data.pivot(index='geo', columns='time')\n",
    "    # incorporate second-level index (indicator name), necessary when merging multiple indicators \n",
    "    data = data.stack(level=0)\n",
    "    data.index.set_names('indicator', level=1, inplace=True)\n",
    "    # dictionary entry: key = indicator name, value = reformatted dataframe\n",
    "    ref[key] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a reference dictionary containing the entire gapminder dataset. As mentioned eariler, this \"everything in one place\" approach is sub-optimal for a number of reasons, one of which will become apparent soon. \n",
    "\n",
    "We will finish the process by concatenating all of these individual tables into a single master dataframe. Again, we ensured that this would go smoothly by reindexing and reshaping in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column names are: Int64Index([1086, 1100, 1279, 1290, 1300, 1309, 1348, 1349, 1351, 1352,\n",
      "            ...\n",
      "            2091, 2092, 2093, 2094, 2095, 2096, 2097, 2098, 2099, 2100],\n",
      "           dtype='int64', name='time', length=409)\n",
      "index names are: ['geo', 'indicator']\n",
      "shape is: (87888, 409)\n",
      "total missing values: 33046225\n",
      "non-missing values: 2899967\n"
     ]
    }
   ],
   "source": [
    "master = pd.concat(ref.values())\n",
    "master = master.sort_index()\n",
    "# let's take a look at some attributes of our master dataframe\n",
    "print(\"column names are:\", master.columns)\n",
    "print(\"index names are:\", master.index.names)\n",
    "print(\"shape is:\", master.shape)\n",
    "print(\"total missing values:\", master.isna().sum().sum())\n",
    "print(\"non-missing values:\", master.count().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Whoa__, this is a bit of a mess. There are datapoints going back all the way to the 11th century, and there are even points out into the future! How is that possible? \n",
    "\n",
    "Furthermore, our table contains over 33 million missing values, and fewer than 3 million actual values. In other words, the majority of our dataframe is pretty much useless.\n",
    "\n",
    "A closer look at our indicators shows that while most of the indicators contain observed values, some are projections. This explains the values for future years. We could fix this by not loading in those particular indicators, or by filtering our data to a specific timeframe. \n",
    "\n",
    "How about those missing values though?  Let's take a closer look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count      409.000000\n",
      "mean      7090.383863\n",
      "std      11610.421421\n",
      "min          1.000000\n",
      "25%         70.000000\n",
      "50%       3874.000000\n",
      "75%       4998.000000\n",
      "max      59140.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(master.count().describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that explains a lot. If there were no values missing in our table, we would expect to see almost 88,000 observations for each year. Here we see that 75% of years contain fewer than 5000 observations, that there is at least one year that contains only 1 single value, and that even the year for which we have the most information still contains almost 30,000 missing values.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  4.,   6.,   8.,   4.,  10.,   7.,   9.,  11.,  25., 325.]),\n",
       " array([28860. , 34773.9, 40687.8, 46601.7, 52515.6, 58429.5, 64343.4,\n",
       "        70257.3, 76171.2, 82085.1, 87999. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('missing observations')\n",
    "plt.ylabel('# of columns')\n",
    "plt.hist(88000 - master.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "In our attempt to put everything in one place, we created a HUGE but mostly empty dataset. The most obvious culprits based on our cursory look are the very early years that contain very few observations, and the future (projection) years which also contain relatively few observations. \n",
    "\n",
    "There are some less obvious complications though:\n",
    "1) Countries whose names change\n",
    "2) Countries for which very little data has been collected\n",
    "3) Indicators which only contain data for a limited timeframe\n",
    "\n",
    "These can each be addressed, whether by \n",
    "1) limiting the scope of analysis to only certain countries, \n",
    "2) certain indicators, or \n",
    "3) certain time-periods \n",
    "\n",
    "Each of these solutions moves us away from the 'everything in one place' approach we were initially going for, but would also prevent the replication of tons of empty values.\n",
    "\n",
    "What follows are two examples of how the assembly process used earlier could have been modified to reduce the size of the dataframe output based on user-determined filtering criteria. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering by time and indicator \n",
    "d1 = {}\n",
    "\n",
    "for filename in datafiles_all:\n",
    "    # read in only filenames containing certain keywords\n",
    "    if re.search('income|cancer.deaths.*100000', filename):\n",
    "        key = filename.partition('datapoints--')[2].partition('--')[0]\n",
    "        data = pd.read_csv(filename)\n",
    "        # 'pre-cleaning' step to exclude data from earlier than 1950, and exclude projections\n",
    "        data = data[data.time >= 1950]\n",
    "        data = data[data.time <= 2018] \n",
    "        data = data.pivot(index='geo', columns='time')\n",
    "        data = data.stack(level=0)\n",
    "        data.index.set_names('indicator', level=1, inplace=True)\n",
    "        d1[key] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering by time and country\n",
    "d2 = {}\n",
    "\n",
    "for filename in datafiles_all:\n",
    "    key = filename.partition('datapoints--')[2].partition('--')[0]\n",
    "    data = pd.read_csv(filename)\n",
    "    data = data[data.time >= 1950]\n",
    "    data = data[data.time <= 2018] \n",
    "    # from each indicator, retain only the data for the following five countries\n",
    "    data = data.loc[(data.geo == 'usa') | (data.geo == 'ger') | (data.geo == 'chi') |\n",
    "                    (data.geo == 'jap') | (data.geo == 'aus')]\n",
    "    data = data.pivot(index='geo', columns='time')\n",
    "    data = data.stack(level=0)\n",
    "    data.index.set_names('indicator', level=1, inplace=True)\n",
    "    d2[key] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column bounds are: (1950, 2018)\n",
      "shape of t1 is: (4547, 69)\n",
      "total missing values in t1: 199787\n",
      "non-missing values in t1: 113956 \n",
      "\n",
      "shape of t2 is: (1004, 69)\n",
      "total missing values in t2: 41420\n",
      "non-missing values in t2: 27856\n"
     ]
    }
   ],
   "source": [
    "t1 = pd.concat(d1.values())\n",
    "t1 = t1.sort_index()\n",
    "print(\"column bounds are:\", (t1.columns.min(), t1.columns.max()))\n",
    "print(\"shape of t1 is:\", t1.shape)\n",
    "print(\"total missing values in t1:\", t1.isna().sum().sum())\n",
    "print(\"non-missing values in t1:\", t1.count().sum(), '\\n')\n",
    "\n",
    "t2 = pd.concat(d2.values())\n",
    "t2 = t2.sort_index()\n",
    "print(\"shape of t2 is:\", t2.shape)\n",
    "print(\"total missing values in t2:\", t2.isna().sum().sum())\n",
    "print(\"non-missing values in t2:\", t2.count().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, by limiting the data we read in during our initial sweep of the datafile directory, we reduced the size of our working datasets, and also dramatically cut down on the number of missing values we would now have to deal with during analysis. \n",
    "\n",
    "Of course, we could accomplish the same thing by simply subsetting our comprehensive (but bloated) 'master' dataset since we've already assembled it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Filtering by time and indicator\n",
    "\n",
    "master_t1 = master.loc[:, 1950:2018].filter(regex='income|cancer.deaths.*100000', axis=0)\n",
    "print(master_t1.shape == t1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Filtering by time and country\n",
    "\n",
    "master_t2 = master.loc[['usa', 'ger', 'chi', 'jap', 'aus'], 1950:2018].dropna(how='all', axis=0)\n",
    "print(master_t2.shape == t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, neither approach is purely 'better' or 'worse', but as noted before, the performance burden of creating a comprehensive dataset could be dramatic with larger multi-dimensional data-sets, so pre-processing is generally preferred. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "> **Tip**: Now that you've trimmed and cleaned your data, you're ready to move on to exploration. Compute statistics and create visualizations with the goal of addressing the research questions that you posed in the Introduction section. It is recommended that you be systematic with your approach. Look at one variable at a time, and then follow it up by looking at relationships between variables.\n",
    "\n",
    "### Research Question 1 (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this, and more code cells, to explore your data. Don't forget to add\n",
    "#   Markdown cells to document your observations and findings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question 2  (Replace this header name!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue to explore the data to address your additional research\n",
    "#   questions. Add more headers as needed if you have more questions to\n",
    "#   investigate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    "> **Tip**: Finally, summarize your findings and the results that have been performed. Make sure that you are clear with regards to the limitations of your exploration. If you haven't done any statistical tests, do not imply any statistical conclusions. And make sure you avoid implying causation from correlation!\n",
    "\n",
    "> **Tip**: Once you are satisfied with your work here, check over your report to make sure that it is satisfies all the areas of the rubric (found on the project submission page at the end of the lesson). You should also probably remove all of the \"Tips\" like this one so that the presentation is as polished as possible.\n",
    "\n",
    "## Submitting your Project \n",
    "\n",
    "> Before you submit your project, you need to create a .html or .pdf version of this notebook in the workspace here. To do that, run the code cell below. If it worked correctly, you should get a return code of 0, and you should see the generated .html file in the workspace directory (click on the orange Jupyter icon in the upper left).\n",
    "\n",
    "> Alternatively, you can download this report as .html via the **File** > **Download as** submenu, and then manually upload it into the workspace directory by clicking on the orange Jupyter icon in the upper left, then using the Upload button.\n",
    "\n",
    "> Once you've done this, you can submit your project by clicking on the \"Submit Project\" button in the lower right here. This will create and submit a zip file with this .ipynb doc and the .html or .pdf version you created. Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Investigate_a_Dataset.ipynb'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
